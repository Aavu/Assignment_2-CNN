Training Epoch: [0][0/22]	Training Loss: 0.037348
Training Epoch: [0][1/22]	Training Loss: 0.038094
Training Epoch: [0][2/22]	Training Loss: 0.036451
Training Epoch: [0][3/22]	Training Loss: 0.032338
Training Epoch: [0][4/22]	Training Loss: 0.029171
Training Epoch: [0][5/22]	Training Loss: 0.032267
Training Epoch: [0][6/22]	Training Loss: 0.038695
Training Epoch: [0][7/22]	Training Loss: 0.035320
Training Epoch: [0][8/22]	Training Loss: 0.033999
Training Epoch: [0][9/22]	Training Loss: 0.040075
Training Epoch: [0][10/22]	Training Loss: 0.035244
Training Epoch: [0][11/22]	Training Loss: 0.031393
Training Epoch: [0][12/22]	Training Loss: 0.032408
Training Epoch: [0][13/22]	Training Loss: 0.029831
Training Epoch: [0][14/22]	Training Loss: 0.031656
Training Epoch: [0][15/22]	Training Loss: 0.031266
Training Epoch: [0][16/22]	Training Loss: 0.030283
Training Epoch: [0][17/22]	Training Loss: 0.030913
Training Epoch: [0][18/22]	Training Loss: 0.030264
Training Epoch: [0][19/22]	Training Loss: 0.032007
Training Epoch: [0][20/22]	Training Loss: 0.030747
Training Epoch: [0][21/22]	Training Loss: 0.030621
Training Epoch: [0][22/22]	Training Loss: 0.029166
Validation Loss: 0.002194 	Validation Acc.: 60.586319
best accuracy: 60.586319218241044
Training Epoch: [1][0/22]	Training Loss: 0.029739
Training Epoch: [1][1/22]	Training Loss: 0.030040
Training Epoch: [1][2/22]	Training Loss: 0.029345
Training Epoch: [1][3/22]	Training Loss: 0.028157
Training Epoch: [1][4/22]	Training Loss: 0.028921
Training Epoch: [1][5/22]	Training Loss: 0.029241
Training Epoch: [1][6/22]	Training Loss: 0.029012
Training Epoch: [1][7/22]	Training Loss: 0.028027
Training Epoch: [1][8/22]	Training Loss: 0.029042
Training Epoch: [1][9/22]	Training Loss: 0.030120
Training Epoch: [1][10/22]	Training Loss: 0.029093
Training Epoch: [1][11/22]	Training Loss: 0.029905
Training Epoch: [1][12/22]	Training Loss: 0.028076
Training Epoch: [1][13/22]	Training Loss: 0.027433
Training Epoch: [1][14/22]	Training Loss: 0.026105
Training Epoch: [1][15/22]	Training Loss: 0.029014
Training Epoch: [1][16/22]	Training Loss: 0.029359
Training Epoch: [1][17/22]	Training Loss: 0.027439
Training Epoch: [1][18/22]	Training Loss: 0.027518
Training Epoch: [1][19/22]	Training Loss: 0.025383
Training Epoch: [1][20/22]	Training Loss: 0.025393
Training Epoch: [1][21/22]	Training Loss: 0.026482
Training Epoch: [1][22/22]	Training Loss: 0.029225
Validation Loss: 0.001984 	Validation Acc.: 63.192182
best accuracy: 63.192182410423456
Training Epoch: [2][0/22]	Training Loss: 0.025029
Training Epoch: [2][1/22]	Training Loss: 0.025826
Training Epoch: [2][2/22]	Training Loss: 0.026845
Training Epoch: [2][3/22]	Training Loss: 0.026120
Training Epoch: [2][4/22]	Training Loss: 0.025905
Training Epoch: [2][5/22]	Training Loss: 0.027648
Training Epoch: [2][6/22]	Training Loss: 0.025975
Training Epoch: [2][7/22]	Training Loss: 0.026928
Training Epoch: [2][8/22]	Training Loss: 0.027187
Training Epoch: [2][9/22]	Training Loss: 0.027229
Training Epoch: [2][10/22]	Training Loss: 0.026067
Training Epoch: [2][11/22]	Training Loss: 0.028008
Training Epoch: [2][12/22]	Training Loss: 0.030937
Training Epoch: [2][13/22]	Training Loss: 0.027637
Training Epoch: [2][14/22]	Training Loss: 0.025925
Training Epoch: [2][15/22]	Training Loss: 0.026283
Training Epoch: [2][16/22]	Training Loss: 0.027323
Training Epoch: [2][17/22]	Training Loss: 0.023477
Training Epoch: [2][18/22]	Training Loss: 0.025150
Training Epoch: [2][19/22]	Training Loss: 0.021412
Training Epoch: [2][20/22]	Training Loss: 0.023870
Training Epoch: [2][21/22]	Training Loss: 0.025389
Training Epoch: [2][22/22]	Training Loss: 0.022136
Validation Loss: 0.001856 	Validation Acc.: 69.381107
best accuracy: 69.38110749185668
Training Epoch: [3][0/22]	Training Loss: 0.020318
Training Epoch: [3][1/22]	Training Loss: 0.026031
Training Epoch: [3][2/22]	Training Loss: 0.026997
Training Epoch: [3][3/22]	Training Loss: 0.022331
Training Epoch: [3][4/22]	Training Loss: 0.021109
Training Epoch: [3][5/22]	Training Loss: 0.023185
Training Epoch: [3][6/22]	Training Loss: 0.026854
Training Epoch: [3][7/22]	Training Loss: 0.024801
Training Epoch: [3][8/22]	Training Loss: 0.024082
Training Epoch: [3][9/22]	Training Loss: 0.022639
Training Epoch: [3][10/22]	Training Loss: 0.024276
Training Epoch: [3][11/22]	Training Loss: 0.026529
Training Epoch: [3][12/22]	Training Loss: 0.026260
Training Epoch: [3][13/22]	Training Loss: 0.023502
Training Epoch: [3][14/22]	Training Loss: 0.026011
Training Epoch: [3][15/22]	Training Loss: 0.022776
Training Epoch: [3][16/22]	Training Loss: 0.023486
Training Epoch: [3][17/22]	Training Loss: 0.023376
Training Epoch: [3][18/22]	Training Loss: 0.021057
Training Epoch: [3][19/22]	Training Loss: 0.022820
Training Epoch: [3][20/22]	Training Loss: 0.022471
Training Epoch: [3][21/22]	Training Loss: 0.026885
Training Epoch: [3][22/22]	Training Loss: 0.019951
Validation Loss: 0.001681 	Validation Acc.: 75.570033
best accuracy: 75.57003257328991
Training Epoch: [4][0/22]	Training Loss: 0.019815
Training Epoch: [4][1/22]	Training Loss: 0.020109
Training Epoch: [4][2/22]	Training Loss: 0.023900
Training Epoch: [4][3/22]	Training Loss: 0.027845
Training Epoch: [4][4/22]	Training Loss: 0.020726
Training Epoch: [4][5/22]	Training Loss: 0.022929
Training Epoch: [4][6/22]	Training Loss: 0.018483
Training Epoch: [4][7/22]	Training Loss: 0.018911
Training Epoch: [4][8/22]	Training Loss: 0.021367
Training Epoch: [4][9/22]	Training Loss: 0.022939
Training Epoch: [4][10/22]	Training Loss: 0.021042
Training Epoch: [4][11/22]	Training Loss: 0.020964
Training Epoch: [4][12/22]	Training Loss: 0.019347
Training Epoch: [4][13/22]	Training Loss: 0.019969
Training Epoch: [4][14/22]	Training Loss: 0.018977
Training Epoch: [4][15/22]	Training Loss: 0.024006
Training Epoch: [4][16/22]	Training Loss: 0.020127
Training Epoch: [4][17/22]	Training Loss: 0.020541
Training Epoch: [4][18/22]	Training Loss: 0.017602
Training Epoch: [4][19/22]	Training Loss: 0.017076
Training Epoch: [4][20/22]	Training Loss: 0.019015
Training Epoch: [4][21/22]	Training Loss: 0.020071
Training Epoch: [4][22/22]	Training Loss: 0.028177
Validation Loss: 0.001373 	Validation Acc.: 85.993485
best accuracy: 85.99348534201954
Training Epoch: [5][0/22]	Training Loss: 0.016925
Training Epoch: [5][1/22]	Training Loss: 0.017268
Training Epoch: [5][2/22]	Training Loss: 0.018600
Training Epoch: [5][3/22]	Training Loss: 0.017043
Training Epoch: [5][4/22]	Training Loss: 0.021524
Training Epoch: [5][5/22]	Training Loss: 0.019071
Training Epoch: [5][6/22]	Training Loss: 0.019643
Training Epoch: [5][7/22]	Training Loss: 0.018745
Training Epoch: [5][8/22]	Training Loss: 0.018432
Training Epoch: [5][9/22]	Training Loss: 0.016049
Training Epoch: [5][10/22]	Training Loss: 0.018700
Training Epoch: [5][11/22]	Training Loss: 0.020622
Training Epoch: [5][12/22]	Training Loss: 0.021714
Training Epoch: [5][13/22]	Training Loss: 0.015046
Training Epoch: [5][14/22]	Training Loss: 0.018885
Training Epoch: [5][15/22]	Training Loss: 0.019882
Training Epoch: [5][16/22]	Training Loss: 0.018720
Training Epoch: [5][17/22]	Training Loss: 0.016893
Training Epoch: [5][18/22]	Training Loss: 0.014186
Training Epoch: [5][19/22]	Training Loss: 0.011577
Training Epoch: [5][20/22]	Training Loss: 0.014082
Training Epoch: [5][21/22]	Training Loss: 0.013046
Training Epoch: [5][22/22]	Training Loss: 0.012574
Validation Loss: 0.001101 	Validation Acc.: 86.970684
best accuracy: 86.97068403908794
Training Epoch: [6][0/22]	Training Loss: 0.015037
Training Epoch: [6][1/22]	Training Loss: 0.013375
Training Epoch: [6][2/22]	Training Loss: 0.011598
Training Epoch: [6][3/22]	Training Loss: 0.013061
Training Epoch: [6][4/22]	Training Loss: 0.013829
Training Epoch: [6][5/22]	Training Loss: 0.014840
Training Epoch: [6][6/22]	Training Loss: 0.011659
Training Epoch: [6][7/22]	Training Loss: 0.016953
Training Epoch: [6][8/22]	Training Loss: 0.011326
Training Epoch: [6][9/22]	Training Loss: 0.011480
Training Epoch: [6][10/22]	Training Loss: 0.012072
Training Epoch: [6][11/22]	Training Loss: 0.014438
Training Epoch: [6][12/22]	Training Loss: 0.011949
Training Epoch: [6][13/22]	Training Loss: 0.010525
Training Epoch: [6][14/22]	Training Loss: 0.011764
Training Epoch: [6][15/22]	Training Loss: 0.014102
Training Epoch: [6][16/22]	Training Loss: 0.009287
Training Epoch: [6][17/22]	Training Loss: 0.012908
Training Epoch: [6][18/22]	Training Loss: 0.016021
Training Epoch: [6][19/22]	Training Loss: 0.013242
Training Epoch: [6][20/22]	Training Loss: 0.013673
Training Epoch: [6][21/22]	Training Loss: 0.009525
Training Epoch: [6][22/22]	Training Loss: 0.010729
Validation Loss: 0.000899 	Validation Acc.: 87.947883
best accuracy: 87.94788273615636
Training Epoch: [7][0/22]	Training Loss: 0.009140
Training Epoch: [7][1/22]	Training Loss: 0.008002
Training Epoch: [7][2/22]	Training Loss: 0.012692
Training Epoch: [7][3/22]	Training Loss: 0.014392
Training Epoch: [7][4/22]	Training Loss: 0.011001
Training Epoch: [7][5/22]	Training Loss: 0.008750
Training Epoch: [7][6/22]	Training Loss: 0.007695
Training Epoch: [7][7/22]	Training Loss: 0.008441
Training Epoch: [7][8/22]	Training Loss: 0.009424
Training Epoch: [7][9/22]	Training Loss: 0.012997
Training Epoch: [7][10/22]	Training Loss: 0.012124
Training Epoch: [7][11/22]	Training Loss: 0.009644
Training Epoch: [7][12/22]	Training Loss: 0.010736
Training Epoch: [7][13/22]	Training Loss: 0.010332
Training Epoch: [7][14/22]	Training Loss: 0.010120
Training Epoch: [7][15/22]	Training Loss: 0.008705
Training Epoch: [7][16/22]	Training Loss: 0.007261
Training Epoch: [7][17/22]	Training Loss: 0.009079
Training Epoch: [7][18/22]	Training Loss: 0.007316
Training Epoch: [7][19/22]	Training Loss: 0.005764
Training Epoch: [7][20/22]	Training Loss: 0.008374
Training Epoch: [7][21/22]	Training Loss: 0.008383
Training Epoch: [7][22/22]	Training Loss: 0.009770
Validation Loss: 0.000760 	Validation Acc.: 91.205212
best accuracy: 91.20521172638436
Training Epoch: [8][0/22]	Training Loss: 0.007941
Training Epoch: [8][1/22]	Training Loss: 0.008257
Training Epoch: [8][2/22]	Training Loss: 0.005902
Training Epoch: [8][3/22]	Training Loss: 0.007787
Training Epoch: [8][4/22]	Training Loss: 0.008884
Training Epoch: [8][5/22]	Training Loss: 0.008765
Training Epoch: [8][6/22]	Training Loss: 0.009916
Training Epoch: [8][7/22]	Training Loss: 0.004343
Training Epoch: [8][8/22]	Training Loss: 0.006805
Training Epoch: [8][9/22]	Training Loss: 0.006064
Training Epoch: [8][10/22]	Training Loss: 0.005004
Training Epoch: [8][11/22]	Training Loss: 0.007369
Training Epoch: [8][12/22]	Training Loss: 0.008284
Training Epoch: [8][13/22]	Training Loss: 0.004971
Training Epoch: [8][14/22]	Training Loss: 0.008814
Training Epoch: [8][15/22]	Training Loss: 0.006553
Training Epoch: [8][16/22]	Training Loss: 0.008924
Training Epoch: [8][17/22]	Training Loss: 0.007595
Training Epoch: [8][18/22]	Training Loss: 0.007492
Training Epoch: [8][19/22]	Training Loss: 0.011727
Training Epoch: [8][20/22]	Training Loss: 0.007424
Training Epoch: [8][21/22]	Training Loss: 0.006384
Training Epoch: [8][22/22]	Training Loss: 0.004598
Validation Loss: 0.000587 	Validation Acc.: 94.462541
best accuracy: 94.46254071661238
Training Epoch: [9][0/22]	Training Loss: 0.008913
Training Epoch: [9][1/22]	Training Loss: 0.004915
Training Epoch: [9][2/22]	Training Loss: 0.005673
Training Epoch: [9][3/22]	Training Loss: 0.008340
Training Epoch: [9][4/22]	Training Loss: 0.005349
Training Epoch: [9][5/22]	Training Loss: 0.005332
Training Epoch: [9][6/22]	Training Loss: 0.005465
Training Epoch: [9][7/22]	Training Loss: 0.007855
Training Epoch: [9][8/22]	Training Loss: 0.007777
Training Epoch: [9][9/22]	Training Loss: 0.006299
Training Epoch: [9][10/22]	Training Loss: 0.005916
Training Epoch: [9][11/22]	Training Loss: 0.006743
Training Epoch: [9][12/22]	Training Loss: 0.007211
Training Epoch: [9][13/22]	Training Loss: 0.004743
Training Epoch: [9][14/22]	Training Loss: 0.006558
Training Epoch: [9][15/22]	Training Loss: 0.009490
Training Epoch: [9][16/22]	Training Loss: 0.006334
Training Epoch: [9][17/22]	Training Loss: 0.004567
Training Epoch: [9][18/22]	Training Loss: 0.004988
Training Epoch: [9][19/22]	Training Loss: 0.005092
Training Epoch: [9][20/22]	Training Loss: 0.009683
Training Epoch: [9][21/22]	Training Loss: 0.006580
Training Epoch: [9][22/22]	Training Loss: 0.002808
Validation Loss: 0.000639 	Validation Acc.: 94.136808
best accuracy: 94.46254071661238
Training Epoch: [10][0/22]	Training Loss: 0.004551
Training Epoch: [10][1/22]	Training Loss: 0.005788
Training Epoch: [10][2/22]	Training Loss: 0.004411
Training Epoch: [10][3/22]	Training Loss: 0.006123
Training Epoch: [10][4/22]	Training Loss: 0.006359
Training Epoch: [10][5/22]	Training Loss: 0.006390
Training Epoch: [10][6/22]	Training Loss: 0.005661
Training Epoch: [10][7/22]	Training Loss: 0.003815
Training Epoch: [10][8/22]	Training Loss: 0.002964
Training Epoch: [10][9/22]	Training Loss: 0.004373
Training Epoch: [10][10/22]	Training Loss: 0.003385
Training Epoch: [10][11/22]	Training Loss: 0.005344
Training Epoch: [10][12/22]	Training Loss: 0.006568
Training Epoch: [10][13/22]	Training Loss: 0.005134
Training Epoch: [10][14/22]	Training Loss: 0.003657
Training Epoch: [10][15/22]	Training Loss: 0.006755
Training Epoch: [10][16/22]	Training Loss: 0.005598
Training Epoch: [10][17/22]	Training Loss: 0.003364
Training Epoch: [10][18/22]	Training Loss: 0.002966
Training Epoch: [10][19/22]	Training Loss: 0.003873
Training Epoch: [10][20/22]	Training Loss: 0.007657
Training Epoch: [10][21/22]	Training Loss: 0.004283
Training Epoch: [10][22/22]	Training Loss: 0.008573
Validation Loss: 0.000568 	Validation Acc.: 96.091205
best accuracy: 96.09120521172639
Training Epoch: [11][0/22]	Training Loss: 0.002928
Training Epoch: [11][1/22]	Training Loss: 0.005604
Training Epoch: [11][2/22]	Training Loss: 0.006092
Training Epoch: [11][3/22]	Training Loss: 0.004274
Training Epoch: [11][4/22]	Training Loss: 0.005831
Training Epoch: [11][5/22]	Training Loss: 0.004859
Training Epoch: [11][6/22]	Training Loss: 0.004617
Training Epoch: [11][7/22]	Training Loss: 0.003833
Training Epoch: [11][8/22]	Training Loss: 0.004645
Training Epoch: [11][9/22]	Training Loss: 0.006149
Training Epoch: [11][10/22]	Training Loss: 0.005522
Training Epoch: [11][11/22]	Training Loss: 0.005890
Training Epoch: [11][12/22]	Training Loss: 0.008649
Training Epoch: [11][13/22]	Training Loss: 0.009141
Training Epoch: [11][14/22]	Training Loss: 0.002270
Training Epoch: [11][15/22]	Training Loss: 0.007677
Training Epoch: [11][16/22]	Training Loss: 0.010609
Training Epoch: [11][17/22]	Training Loss: 0.006965
Training Epoch: [11][18/22]	Training Loss: 0.002954
Training Epoch: [11][19/22]	Training Loss: 0.003420
Training Epoch: [11][20/22]	Training Loss: 0.004968
Training Epoch: [11][21/22]	Training Loss: 0.006973
Training Epoch: [11][22/22]	Training Loss: 0.003494
Validation Loss: 0.000689 	Validation Acc.: 95.114007
best accuracy: 96.09120521172639
Training Epoch: [12][0/22]	Training Loss: 0.004360
Training Epoch: [12][1/22]	Training Loss: 0.004871
Training Epoch: [12][2/22]	Training Loss: 0.003138
Training Epoch: [12][3/22]	Training Loss: 0.003404
Training Epoch: [12][4/22]	Training Loss: 0.004898
Training Epoch: [12][5/22]	Training Loss: 0.004908
Training Epoch: [12][6/22]	Training Loss: 0.005339
Training Epoch: [12][7/22]	Training Loss: 0.005104
Training Epoch: [12][8/22]	Training Loss: 0.004718
Training Epoch: [12][9/22]	Training Loss: 0.005084
Training Epoch: [12][10/22]	Training Loss: 0.003502
Training Epoch: [12][11/22]	Training Loss: 0.003541
Training Epoch: [12][12/22]	Training Loss: 0.015589
Training Epoch: [12][13/22]	Training Loss: 0.005210
Training Epoch: [12][14/22]	Training Loss: 0.003517
Training Epoch: [12][15/22]	Training Loss: 0.019268
Training Epoch: [12][16/22]	Training Loss: 0.002466
Training Epoch: [12][17/22]	Training Loss: 0.006098
Training Epoch: [12][18/22]	Training Loss: 0.009502
Training Epoch: [12][19/22]	Training Loss: 0.005048
Training Epoch: [12][20/22]	Training Loss: 0.004559
Training Epoch: [12][21/22]	Training Loss: 0.004676
Training Epoch: [12][22/22]	Training Loss: 0.003121
Validation Loss: 0.000961 	Validation Acc.: 93.159609
best accuracy: 96.09120521172639
Training Epoch: [13][0/22]	Training Loss: 0.003399
Training Epoch: [13][1/22]	Training Loss: 0.007297
Training Epoch: [13][2/22]	Training Loss: 0.010810
Training Epoch: [13][3/22]	Training Loss: 0.002467
Training Epoch: [13][4/22]	Training Loss: 0.004432
Training Epoch: [13][5/22]	Training Loss: 0.004961
Training Epoch: [13][6/22]	Training Loss: 0.023034
Training Epoch: [13][7/22]	Training Loss: 0.006141
Training Epoch: [13][8/22]	Training Loss: 0.003546
Training Epoch: [13][9/22]	Training Loss: 0.014264
Training Epoch: [13][10/22]	Training Loss: 0.005853
Training Epoch: [13][11/22]	Training Loss: 0.007769
Training Epoch: [13][12/22]	Training Loss: 0.002801
Training Epoch: [13][13/22]	Training Loss: 0.004902
Training Epoch: [13][14/22]	Training Loss: 0.027496
Training Epoch: [13][15/22]	Training Loss: 0.010171
Training Epoch: [13][16/22]	Training Loss: 0.004990
Training Epoch: [13][17/22]	Training Loss: 0.021938
Training Epoch: [13][18/22]	Training Loss: 0.003742
Training Epoch: [13][19/22]	Training Loss: 0.004455
Training Epoch: [13][20/22]	Training Loss: 0.007153
Training Epoch: [13][21/22]	Training Loss: 0.008256
Training Epoch: [13][22/22]	Training Loss: 0.006050
Validation Loss: 0.000577 	Validation Acc.: 95.114007
best accuracy: 96.09120521172639
Training Epoch: [14][0/22]	Training Loss: 0.005425
Training Epoch: [14][1/22]	Training Loss: 0.001341
Training Epoch: [14][2/22]	Training Loss: 0.005264
Training Epoch: [14][3/22]	Training Loss: 0.010965
Training Epoch: [14][4/22]	Training Loss: 0.011022
Training Epoch: [14][5/22]	Training Loss: 0.004573
Training Epoch: [14][6/22]	Training Loss: 0.004416
Training Epoch: [14][7/22]	Training Loss: 0.009793
Training Epoch: [14][8/22]	Training Loss: 0.006703
Training Epoch: [14][9/22]	Training Loss: 0.005394
Training Epoch: [14][10/22]	Training Loss: 0.004829
Training Epoch: [14][11/22]	Training Loss: 0.010066
Training Epoch: [14][12/22]	Training Loss: 0.002900
Training Epoch: [14][13/22]	Training Loss: 0.004720
Training Epoch: [14][14/22]	Training Loss: 0.001923
Training Epoch: [14][15/22]	Training Loss: 0.005341
Training Epoch: [14][16/22]	Training Loss: 0.009291
Training Epoch: [14][17/22]	Training Loss: 0.003798
Training Epoch: [14][18/22]	Training Loss: 0.003667
Training Epoch: [14][19/22]	Training Loss: 0.003809
Training Epoch: [14][20/22]	Training Loss: 0.006339
Training Epoch: [14][21/22]	Training Loss: 0.007107
Training Epoch: [14][22/22]	Training Loss: 0.009298
Validation Loss: 0.000803 	Validation Acc.: 93.811075
best accuracy: 96.09120521172639
Training Epoch: [15][0/22]	Training Loss: 0.003626
Training Epoch: [15][1/22]	Training Loss: 0.006697
Training Epoch: [15][2/22]	Training Loss: 0.013843
Training Epoch: [15][3/22]	Training Loss: 0.004963
Training Epoch: [15][4/22]	Training Loss: 0.005102
Training Epoch: [15][5/22]	Training Loss: 0.007119
Training Epoch: [15][6/22]	Training Loss: 0.020525
Training Epoch: [15][7/22]	Training Loss: 0.004066
Training Epoch: [15][8/22]	Training Loss: 0.004945
Training Epoch: [15][9/22]	Training Loss: 0.003357
Training Epoch: [15][10/22]	Training Loss: 0.008378
Training Epoch: [15][11/22]	Training Loss: 0.010170
Training Epoch: [15][12/22]	Training Loss: 0.003670
Training Epoch: [15][13/22]	Training Loss: 0.007988
Training Epoch: [15][14/22]	Training Loss: 0.007467
Training Epoch: [15][15/22]	Training Loss: 0.013742
Training Epoch: [15][16/22]	Training Loss: 0.005175
Training Epoch: [15][17/22]	Training Loss: 0.003688
Training Epoch: [15][18/22]	Training Loss: 0.006247
Training Epoch: [15][19/22]	Training Loss: 0.006188
Training Epoch: [15][20/22]	Training Loss: 0.006450
Training Epoch: [15][21/22]	Training Loss: 0.018046
Training Epoch: [15][22/22]	Training Loss: 0.004681
Validation Loss: 0.000552 	Validation Acc.: 96.742671
best accuracy: 96.74267100977198
Training Epoch: [16][0/22]	Training Loss: 0.003682
Training Epoch: [16][1/22]	Training Loss: 0.007406
Training Epoch: [16][2/22]	Training Loss: 0.009786
Training Epoch: [16][3/22]	Training Loss: 0.017385
Training Epoch: [16][4/22]	Training Loss: 0.008878
Training Epoch: [16][5/22]	Training Loss: 0.007814
Training Epoch: [16][6/22]	Training Loss: 0.006998
Training Epoch: [16][7/22]	Training Loss: 0.002476
Training Epoch: [16][8/22]	Training Loss: 0.009506
Training Epoch: [16][9/22]	Training Loss: 0.015050
Training Epoch: [16][10/22]	Training Loss: 0.005015
Training Epoch: [16][11/22]	Training Loss: 0.003075
Training Epoch: [16][12/22]	Training Loss: 0.002898
Training Epoch: [16][13/22]	Training Loss: 0.006055
Training Epoch: [16][14/22]	Training Loss: 0.018945
Training Epoch: [16][15/22]	Training Loss: 0.010078
Training Epoch: [16][16/22]	Training Loss: 0.009989
Training Epoch: [16][17/22]	Training Loss: 0.006456
Training Epoch: [16][18/22]	Training Loss: 0.006402
Training Epoch: [16][19/22]	Training Loss: 0.005490
Training Epoch: [16][20/22]	Training Loss: 0.012959
Training Epoch: [16][21/22]	Training Loss: 0.011368
Training Epoch: [16][22/22]	Training Loss: 0.004980
Validation Loss: 0.000625 	Validation Acc.: 96.091205
best accuracy: 96.74267100977198
Training Epoch: [17][0/22]	Training Loss: 0.003348
Training Epoch: [17][1/22]	Training Loss: 0.003238
Training Epoch: [17][2/22]	Training Loss: 0.005007
Training Epoch: [17][3/22]	Training Loss: 0.005738
Training Epoch: [17][4/22]	Training Loss: 0.008098
Training Epoch: [17][5/22]	Training Loss: 0.006054
Training Epoch: [17][6/22]	Training Loss: 0.011194
Training Epoch: [17][7/22]	Training Loss: 0.004126
Training Epoch: [17][8/22]	Training Loss: 0.005755
Training Epoch: [17][9/22]	Training Loss: 0.003258
Training Epoch: [17][10/22]	Training Loss: 0.002551
Training Epoch: [17][11/22]	Training Loss: 0.003621
Training Epoch: [17][12/22]	Training Loss: 0.004948
Training Epoch: [17][13/22]	Training Loss: 0.011766
Training Epoch: [17][14/22]	Training Loss: 0.011631
Training Epoch: [17][15/22]	Training Loss: 0.002952
Training Epoch: [17][16/22]	Training Loss: 0.003917
Training Epoch: [17][17/22]	Training Loss: 0.003621
Training Epoch: [17][18/22]	Training Loss: 0.004938
Training Epoch: [17][19/22]	Training Loss: 0.018427
Training Epoch: [17][20/22]	Training Loss: 0.005729
Training Epoch: [17][21/22]	Training Loss: 0.008301
Training Epoch: [17][22/22]	Training Loss: 0.003482
Validation Loss: 0.000570 	Validation Acc.: 95.439739
best accuracy: 96.74267100977198
Training Epoch: [18][0/22]	Training Loss: 0.003151
Training Epoch: [18][1/22]	Training Loss: 0.005131
Training Epoch: [18][2/22]	Training Loss: 0.007732
Training Epoch: [18][3/22]	Training Loss: 0.006973
Training Epoch: [18][4/22]	Training Loss: 0.013792
Training Epoch: [18][5/22]	Training Loss: 0.005371
Training Epoch: [18][6/22]	Training Loss: 0.003031
Training Epoch: [18][7/22]	Training Loss: 0.003587
Training Epoch: [18][8/22]	Training Loss: 0.010082
Training Epoch: [18][9/22]	Training Loss: 0.009846
Training Epoch: [18][10/22]	Training Loss: 0.005314
Training Epoch: [18][11/22]	Training Loss: 0.003891
Training Epoch: [18][12/22]	Training Loss: 0.003402
Training Epoch: [18][13/22]	Training Loss: 0.004939
Training Epoch: [18][14/22]	Training Loss: 0.004743
Training Epoch: [18][15/22]	Training Loss: 0.004649
Training Epoch: [18][16/22]	Training Loss: 0.016354
Training Epoch: [18][17/22]	Training Loss: 0.008807
Training Epoch: [18][18/22]	Training Loss: 0.003922
Training Epoch: [18][19/22]	Training Loss: 0.002333
Training Epoch: [18][20/22]	Training Loss: 0.004857
Training Epoch: [18][21/22]	Training Loss: 0.002968
Training Epoch: [18][22/22]	Training Loss: 0.003700
Validation Loss: 0.000504 	Validation Acc.: 97.394137
best accuracy: 97.39413680781759
Training Epoch: [19][0/22]	Training Loss: 0.004102
Training Epoch: [19][1/22]	Training Loss: 0.004179
Training Epoch: [19][2/22]	Training Loss: 0.004678
Training Epoch: [19][3/22]	Training Loss: 0.006664
Training Epoch: [19][4/22]	Training Loss: 0.004875
Training Epoch: [19][5/22]	Training Loss: 0.003486
Training Epoch: [19][6/22]	Training Loss: 0.002406
Training Epoch: [19][7/22]	Training Loss: 0.005663
Training Epoch: [19][8/22]	Training Loss: 0.003594
Training Epoch: [19][9/22]	Training Loss: 0.003031
Training Epoch: [19][10/22]	Training Loss: 0.003982
Training Epoch: [19][11/22]	Training Loss: 0.005202
Training Epoch: [19][12/22]	Training Loss: 0.008092
Training Epoch: [19][13/22]	Training Loss: 0.003156
Training Epoch: [19][14/22]	Training Loss: 0.004373
Training Epoch: [19][15/22]	Training Loss: 0.003675
Training Epoch: [19][16/22]	Training Loss: 0.006681
Training Epoch: [19][17/22]	Training Loss: 0.003811
Training Epoch: [19][18/22]	Training Loss: 0.003015
Training Epoch: [19][19/22]	Training Loss: 0.001952
Training Epoch: [19][20/22]	Training Loss: 0.001359
Training Epoch: [19][21/22]	Training Loss: 0.001342
Training Epoch: [19][22/22]	Training Loss: 0.003501
Validation Loss: 0.000437 	Validation Acc.: 98.371336
best accuracy: 98.37133550488599
Training Epoch: [20][0/22]	Training Loss: 0.003018
Training Epoch: [20][1/22]	Training Loss: 0.004497
Training Epoch: [20][2/22]	Training Loss: 0.003120
Training Epoch: [20][3/22]	Training Loss: 0.004085
Training Epoch: [20][4/22]	Training Loss: 0.004900
Training Epoch: [20][5/22]	Training Loss: 0.002612
Training Epoch: [20][6/22]	Training Loss: 0.002408
Training Epoch: [20][7/22]	Training Loss: 0.003140
Training Epoch: [20][8/22]	Training Loss: 0.002777
Training Epoch: [20][9/22]	Training Loss: 0.002224
Training Epoch: [20][10/22]	Training Loss: 0.002327
Training Epoch: [20][11/22]	Training Loss: 0.001475
Training Epoch: [20][12/22]	Training Loss: 0.002863
Training Epoch: [20][13/22]	Training Loss: 0.003170
Training Epoch: [20][14/22]	Training Loss: 0.002955
Training Epoch: [20][15/22]	Training Loss: 0.004150
Training Epoch: [20][16/22]	Training Loss: 0.003855
Training Epoch: [20][17/22]	Training Loss: 0.003365
Training Epoch: [20][18/22]	Training Loss: 0.002232
Training Epoch: [20][19/22]	Training Loss: 0.001618
Training Epoch: [20][20/22]	Training Loss: 0.002230
Training Epoch: [20][21/22]	Training Loss: 0.002574
Training Epoch: [20][22/22]	Training Loss: 0.001952
Validation Loss: 0.000439 	Validation Acc.: 99.022801
best accuracy: 99.0228013029316
Training Epoch: [21][0/22]	Training Loss: 0.001542
Training Epoch: [21][1/22]	Training Loss: 0.003352
Training Epoch: [21][2/22]	Training Loss: 0.002220
Training Epoch: [21][3/22]	Training Loss: 0.002737
Training Epoch: [21][4/22]	Training Loss: 0.002474
Training Epoch: [21][5/22]	Training Loss: 0.003811
Training Epoch: [21][6/22]	Training Loss: 0.002914
Training Epoch: [21][7/22]	Training Loss: 0.002345
Training Epoch: [21][8/22]	Training Loss: 0.002934
Training Epoch: [21][9/22]	Training Loss: 0.001481
Training Epoch: [21][10/22]	Training Loss: 0.002604
Training Epoch: [21][11/22]	Training Loss: 0.001885
Training Epoch: [21][12/22]	Training Loss: 0.002249
Training Epoch: [21][13/22]	Training Loss: 0.003026
Training Epoch: [21][14/22]	Training Loss: 0.002380
Training Epoch: [21][15/22]	Training Loss: 0.004125
Training Epoch: [21][16/22]	Training Loss: 0.001505
Training Epoch: [21][17/22]	Training Loss: 0.001530
Training Epoch: [21][18/22]	Training Loss: 0.003566
Training Epoch: [21][19/22]	Training Loss: 0.000983
Training Epoch: [21][20/22]	Training Loss: 0.001408
Training Epoch: [21][21/22]	Training Loss: 0.002018
Training Epoch: [21][22/22]	Training Loss: 0.000982
Validation Loss: 0.000462 	Validation Acc.: 98.697068
best accuracy: 99.0228013029316
Training Epoch: [22][0/22]	Training Loss: 0.001082
Training Epoch: [22][1/22]	Training Loss: 0.001259
Training Epoch: [22][2/22]	Training Loss: 0.000953
Training Epoch: [22][3/22]	Training Loss: 0.003719
Training Epoch: [22][4/22]	Training Loss: 0.001621
Training Epoch: [22][5/22]	Training Loss: 0.002640
Training Epoch: [22][6/22]	Training Loss: 0.001642
Training Epoch: [22][7/22]	Training Loss: 0.003276
Training Epoch: [22][8/22]	Training Loss: 0.001862
Training Epoch: [22][9/22]	Training Loss: 0.002304
Training Epoch: [22][10/22]	Training Loss: 0.001548
Training Epoch: [22][11/22]	Training Loss: 0.001320
Training Epoch: [22][12/22]	Training Loss: 0.001175
Training Epoch: [22][13/22]	Training Loss: 0.001513
Training Epoch: [22][14/22]	Training Loss: 0.001771
Training Epoch: [22][15/22]	Training Loss: 0.002832
Training Epoch: [22][16/22]	Training Loss: 0.001906
Training Epoch: [22][17/22]	Training Loss: 0.001411
Training Epoch: [22][18/22]	Training Loss: 0.001552
Training Epoch: [22][19/22]	Training Loss: 0.002568
Training Epoch: [22][20/22]	Training Loss: 0.001989
Training Epoch: [22][21/22]	Training Loss: 0.004302
Training Epoch: [22][22/22]	Training Loss: 0.001777
Validation Loss: 0.000409 	Validation Acc.: 98.697068
best accuracy: 99.0228013029316
Training Epoch: [23][0/22]	Training Loss: 0.001738
Training Epoch: [23][1/22]	Training Loss: 0.001605
Training Epoch: [23][2/22]	Training Loss: 0.003647
Training Epoch: [23][3/22]	Training Loss: 0.001409
Training Epoch: [23][4/22]	Training Loss: 0.002487
Training Epoch: [23][5/22]	Training Loss: 0.000809
Training Epoch: [23][6/22]	Training Loss: 0.001250
Training Epoch: [23][7/22]	Training Loss: 0.003737
Training Epoch: [23][8/22]	Training Loss: 0.001361
Training Epoch: [23][9/22]	Training Loss: 0.000733
Training Epoch: [23][10/22]	Training Loss: 0.001466
Training Epoch: [23][11/22]	Training Loss: 0.002019
Training Epoch: [23][12/22]	Training Loss: 0.001451
Training Epoch: [23][13/22]	Training Loss: 0.002044
Training Epoch: [23][14/22]	Training Loss: 0.000887
Training Epoch: [23][15/22]	Training Loss: 0.002766
Training Epoch: [23][16/22]	Training Loss: 0.001289
Training Epoch: [23][17/22]	Training Loss: 0.002616
Training Epoch: [23][18/22]	Training Loss: 0.001982
Training Epoch: [23][19/22]	Training Loss: 0.001344
Training Epoch: [23][20/22]	Training Loss: 0.001680
Training Epoch: [23][21/22]	Training Loss: 0.001201
Training Epoch: [23][22/22]	Training Loss: 0.001784
Validation Loss: 0.000524 	Validation Acc.: 98.697068
best accuracy: 99.0228013029316
Training Epoch: [24][0/22]	Training Loss: 0.001298
Training Epoch: [24][1/22]	Training Loss: 0.001785
Training Epoch: [24][2/22]	Training Loss: 0.000992
Training Epoch: [24][3/22]	Training Loss: 0.001350
Training Epoch: [24][4/22]	Training Loss: 0.001199
Training Epoch: [24][5/22]	Training Loss: 0.001308
Training Epoch: [24][6/22]	Training Loss: 0.000834
Training Epoch: [24][7/22]	Training Loss: 0.000974
Training Epoch: [24][8/22]	Training Loss: 0.002191
Training Epoch: [24][9/22]	Training Loss: 0.002390
Training Epoch: [24][10/22]	Training Loss: 0.000572
Training Epoch: [24][11/22]	Training Loss: 0.000712
Training Epoch: [24][12/22]	Training Loss: 0.003192
Training Epoch: [24][13/22]	Training Loss: 0.001366
Training Epoch: [24][14/22]	Training Loss: 0.001180
Training Epoch: [24][15/22]	Training Loss: 0.002281
Training Epoch: [24][16/22]	Training Loss: 0.000555
Training Epoch: [24][17/22]	Training Loss: 0.002657
Training Epoch: [24][18/22]	Training Loss: 0.001998
Training Epoch: [24][19/22]	Training Loss: 0.002173
Training Epoch: [24][20/22]	Training Loss: 0.003535
Training Epoch: [24][21/22]	Training Loss: 0.001941
Training Epoch: [24][22/22]	Training Loss: 0.000719
Validation Loss: 0.000579 	Validation Acc.: 98.371336
best accuracy: 99.0228013029316
Training Epoch: [25][0/22]	Training Loss: 0.001230
Training Epoch: [25][1/22]	Training Loss: 0.001868
Training Epoch: [25][2/22]	Training Loss: 0.001247
Training Epoch: [25][3/22]	Training Loss: 0.000730
Training Epoch: [25][4/22]	Training Loss: 0.004069
Training Epoch: [25][5/22]	Training Loss: 0.001682
Training Epoch: [25][6/22]	Training Loss: 0.003011
Training Epoch: [25][7/22]	Training Loss: 0.000751
Training Epoch: [25][8/22]	Training Loss: 0.002179
Training Epoch: [25][9/22]	Training Loss: 0.001755
Training Epoch: [25][10/22]	Training Loss: 0.001907
Training Epoch: [25][11/22]	Training Loss: 0.001923
Training Epoch: [25][12/22]	Training Loss: 0.002561
Training Epoch: [25][13/22]	Training Loss: 0.002926
Training Epoch: [25][14/22]	Training Loss: 0.002175
Training Epoch: [25][15/22]	Training Loss: 0.000946
Training Epoch: [25][16/22]	Training Loss: 0.001287
Training Epoch: [25][17/22]	Training Loss: 0.011887
Training Epoch: [25][18/22]	Training Loss: 0.002989
Training Epoch: [25][19/22]	Training Loss: 0.002486
Training Epoch: [25][20/22]	Training Loss: 0.001297
Training Epoch: [25][21/22]	Training Loss: 0.001780
Training Epoch: [25][22/22]	Training Loss: 0.004765
Validation Loss: 0.001193 	Validation Acc.: 96.416938
best accuracy: 99.0228013029316
Training Epoch: [26][0/22]	Training Loss: 0.001678
Training Epoch: [26][1/22]	Training Loss: 0.000593
Training Epoch: [26][2/22]	Training Loss: 0.027180
Training Epoch: [26][3/22]	Training Loss: 0.005075
Training Epoch: [26][4/22]	Training Loss: 0.001274
Training Epoch: [26][5/22]	Training Loss: 0.002238
Training Epoch: [26][6/22]	Training Loss: 0.019447
Training Epoch: [26][7/22]	Training Loss: 0.005467
Training Epoch: [26][8/22]	Training Loss: 0.003618
Training Epoch: [26][9/22]	Training Loss: 0.002643
Training Epoch: [26][10/22]	Training Loss: 0.002229
Training Epoch: [26][11/22]	Training Loss: 0.000197
Training Epoch: [26][12/22]	Training Loss: 0.002401
Training Epoch: [26][13/22]	Training Loss: 0.003669
Training Epoch: [26][14/22]	Training Loss: 0.010802
Training Epoch: [26][15/22]	Training Loss: 0.006103
Training Epoch: [26][16/22]	Training Loss: 0.001476
Training Epoch: [26][17/22]	Training Loss: 0.006838
Training Epoch: [26][18/22]	Training Loss: 0.017949
Training Epoch: [26][19/22]	Training Loss: 0.013262
Training Epoch: [26][20/22]	Training Loss: 0.003766
Training Epoch: [26][21/22]	Training Loss: 0.003632
Training Epoch: [26][22/22]	Training Loss: 0.005981
Validation Loss: 0.002043 	Validation Acc.: 91.205212
best accuracy: 99.0228013029316
Training Epoch: [27][0/22]	Training Loss: 0.011402
Training Epoch: [27][1/22]	Training Loss: 0.002757
Training Epoch: [27][2/22]	Training Loss: 0.003997
Training Epoch: [27][3/22]	Training Loss: 0.002212
Training Epoch: [27][4/22]	Training Loss: 0.000760
Training Epoch: [27][5/22]	Training Loss: 0.002212
Training Epoch: [27][6/22]	Training Loss: 0.003629
Training Epoch: [27][7/22]	Training Loss: 0.003903
Training Epoch: [27][8/22]	Training Loss: 0.008901
Training Epoch: [27][9/22]	Training Loss: 0.007776
Training Epoch: [27][10/22]	Training Loss: 0.007385
Training Epoch: [27][11/22]	Training Loss: 0.002428
Training Epoch: [27][12/22]	Training Loss: 0.001707
Training Epoch: [27][13/22]	Training Loss: 0.005228
Training Epoch: [27][14/22]	Training Loss: 0.004667
Training Epoch: [27][15/22]	Training Loss: 0.001816
Training Epoch: [27][16/22]	Training Loss: 0.005394
Training Epoch: [27][17/22]	Training Loss: 0.003551
Training Epoch: [27][18/22]	Training Loss: 0.002151
Training Epoch: [27][19/22]	Training Loss: 0.001324
Training Epoch: [27][20/22]	Training Loss: 0.002435
Training Epoch: [27][21/22]	Training Loss: 0.004106
Training Epoch: [27][22/22]	Training Loss: 0.001117
Validation Loss: 0.000593 	Validation Acc.: 97.394137
best accuracy: 99.0228013029316
Training Epoch: [28][0/22]	Training Loss: 0.001575
Training Epoch: [28][1/22]	Training Loss: 0.002315
Training Epoch: [28][2/22]	Training Loss: 0.001640
Training Epoch: [28][3/22]	Training Loss: 0.002776
Training Epoch: [28][4/22]	Training Loss: 0.004546
Training Epoch: [28][5/22]	Training Loss: 0.005498
Training Epoch: [28][6/22]	Training Loss: 0.001850
Training Epoch: [28][7/22]	Training Loss: 0.002169
Training Epoch: [28][8/22]	Training Loss: 0.002027
Training Epoch: [28][9/22]	Training Loss: 0.003074
Training Epoch: [28][10/22]	Training Loss: 0.002861
Training Epoch: [28][11/22]	Training Loss: 0.010664
Training Epoch: [28][12/22]	Training Loss: 0.002363
Training Epoch: [28][13/22]	Training Loss: 0.002568
Training Epoch: [28][14/22]	Training Loss: 0.002475
Training Epoch: [28][15/22]	Training Loss: 0.001977
Training Epoch: [28][16/22]	Training Loss: 0.003549
Training Epoch: [28][17/22]	Training Loss: 0.002345
Training Epoch: [28][18/22]	Training Loss: 0.002780
Training Epoch: [28][19/22]	Training Loss: 0.009988
Training Epoch: [28][20/22]	Training Loss: 0.001999
Training Epoch: [28][21/22]	Training Loss: 0.004530
Training Epoch: [28][22/22]	Training Loss: 0.001614
Validation Loss: 0.000605 	Validation Acc.: 97.394137
best accuracy: 99.0228013029316
Training Epoch: [29][0/22]	Training Loss: 0.000830
Training Epoch: [29][1/22]	Training Loss: 0.001622
Training Epoch: [29][2/22]	Training Loss: 0.004865
Training Epoch: [29][3/22]	Training Loss: 0.002585
Training Epoch: [29][4/22]	Training Loss: 0.001016
Training Epoch: [29][5/22]	Training Loss: 0.005142
Training Epoch: [29][6/22]	Training Loss: 0.004432
Training Epoch: [29][7/22]	Training Loss: 0.001459
Training Epoch: [29][8/22]	Training Loss: 0.003321
Training Epoch: [29][9/22]	Training Loss: 0.002331
Training Epoch: [29][10/22]	Training Loss: 0.003875
Training Epoch: [29][11/22]	Training Loss: 0.001616
Training Epoch: [29][12/22]	Training Loss: 0.002369
Training Epoch: [29][13/22]	Training Loss: 0.007061
Training Epoch: [29][14/22]	Training Loss: 0.002364
Training Epoch: [29][15/22]	Training Loss: 0.010492
Training Epoch: [29][16/22]	Training Loss: 0.002962
Training Epoch: [29][17/22]	Training Loss: 0.003067
Training Epoch: [29][18/22]	Training Loss: 0.002087
Training Epoch: [29][19/22]	Training Loss: 0.001441
Training Epoch: [29][20/22]	Training Loss: 0.001822
Training Epoch: [29][21/22]	Training Loss: 0.002049
Training Epoch: [29][22/22]	Training Loss: 0.008541
Validation Loss: 0.001271 	Validation Acc.: 95.439739
best accuracy: 99.0228013029316
Training Epoch: [30][0/22]	Training Loss: 0.000747
Training Epoch: [30][1/22]	Training Loss: 0.003666
Training Epoch: [30][2/22]	Training Loss: 0.002474
Training Epoch: [30][3/22]	Training Loss: 0.001921
Training Epoch: [30][4/22]	Training Loss: 0.002658
Training Epoch: [30][5/22]	Training Loss: 0.000629
Training Epoch: [30][6/22]	Training Loss: 0.001426
Training Epoch: [30][7/22]	Training Loss: 0.001365
Training Epoch: [30][8/22]	Training Loss: 0.001715
Training Epoch: [30][9/22]	Training Loss: 0.002131
Training Epoch: [30][10/22]	Training Loss: 0.004012
Training Epoch: [30][11/22]	Training Loss: 0.001431
Training Epoch: [30][12/22]	Training Loss: 0.002948
Training Epoch: [30][13/22]	Training Loss: 0.002161
Training Epoch: [30][14/22]	Training Loss: 0.003178
Training Epoch: [30][15/22]	Training Loss: 0.001804
Training Epoch: [30][16/22]	Training Loss: 0.001646
Training Epoch: [30][17/22]	Training Loss: 0.002408
Training Epoch: [30][18/22]	Training Loss: 0.002653
Training Epoch: [30][19/22]	Training Loss: 0.001166
Training Epoch: [30][20/22]	Training Loss: 0.001669
Training Epoch: [30][21/22]	Training Loss: 0.000943
Training Epoch: [30][22/22]	Training Loss: 0.000850
Validation Loss: 0.000381 	Validation Acc.: 98.371336
best accuracy: 99.0228013029316
Training Epoch: [31][0/22]	Training Loss: 0.003937
Training Epoch: [31][1/22]	Training Loss: 0.001647
Training Epoch: [31][2/22]	Training Loss: 0.002153
Training Epoch: [31][3/22]	Training Loss: 0.002097
Training Epoch: [31][4/22]	Training Loss: 0.002311
Training Epoch: [31][5/22]	Training Loss: 0.001024
Training Epoch: [31][6/22]	Training Loss: 0.000561
Training Epoch: [31][7/22]	Training Loss: 0.000636
Training Epoch: [31][8/22]	Training Loss: 0.001430
Training Epoch: [31][9/22]	Training Loss: 0.001902
Training Epoch: [31][10/22]	Training Loss: 0.001892
Training Epoch: [31][11/22]	Training Loss: 0.001355
Training Epoch: [31][12/22]	Training Loss: 0.001054
Training Epoch: [31][13/22]	Training Loss: 0.001145
Training Epoch: [31][14/22]	Training Loss: 0.001307
Training Epoch: [31][15/22]	Training Loss: 0.002059
Training Epoch: [31][16/22]	Training Loss: 0.001067
Training Epoch: [31][17/22]	Training Loss: 0.001663
Training Epoch: [31][18/22]	Training Loss: 0.001771
Training Epoch: [31][19/22]	Training Loss: 0.002147
Training Epoch: [31][20/22]	Training Loss: 0.000912
Training Epoch: [31][21/22]	Training Loss: 0.001501
Training Epoch: [31][22/22]	Training Loss: 0.001815
Validation Loss: 0.000459 	Validation Acc.: 97.719870
best accuracy: 99.0228013029316
Training Epoch: [32][0/22]	Training Loss: 0.001423
Training Epoch: [32][1/22]	Training Loss: 0.001952
Training Epoch: [32][2/22]	Training Loss: 0.001695
Training Epoch: [32][3/22]	Training Loss: 0.000602
Training Epoch: [32][4/22]	Training Loss: 0.000527
Training Epoch: [32][5/22]	Training Loss: 0.000897
Training Epoch: [32][6/22]	Training Loss: 0.001216
Training Epoch: [32][7/22]	Training Loss: 0.001235
Training Epoch: [32][8/22]	Training Loss: 0.000716
Training Epoch: [32][9/22]	Training Loss: 0.000835
Training Epoch: [32][10/22]	Training Loss: 0.001350
Training Epoch: [32][11/22]	Training Loss: 0.001207
Training Epoch: [32][12/22]	Training Loss: 0.001892
Training Epoch: [32][13/22]	Training Loss: 0.002787
Training Epoch: [32][14/22]	Training Loss: 0.001890
Training Epoch: [32][15/22]	Training Loss: 0.001562
Training Epoch: [32][16/22]	Training Loss: 0.002101
Training Epoch: [32][17/22]	Training Loss: 0.002274
Training Epoch: [32][18/22]	Training Loss: 0.001790
Training Epoch: [32][19/22]	Training Loss: 0.000285
Training Epoch: [32][20/22]	Training Loss: 0.000710
Training Epoch: [32][21/22]	Training Loss: 0.000747
Training Epoch: [32][22/22]	Training Loss: 0.002811
Validation Loss: 0.000600 	Validation Acc.: 97.719870
best accuracy: 99.0228013029316
Training Epoch: [33][0/22]	Training Loss: 0.000321
Training Epoch: [33][1/22]	Training Loss: 0.001573
Training Epoch: [33][2/22]	Training Loss: 0.000781
Training Epoch: [33][3/22]	Training Loss: 0.000418
Training Epoch: [33][4/22]	Training Loss: 0.001328
Training Epoch: [33][5/22]	Training Loss: 0.001361
Training Epoch: [33][6/22]	Training Loss: 0.002887
Training Epoch: [33][7/22]	Training Loss: 0.001199
Training Epoch: [33][8/22]	Training Loss: 0.002386
Training Epoch: [33][9/22]	Training Loss: 0.000575
Training Epoch: [33][10/22]	Training Loss: 0.000942
Training Epoch: [33][11/22]	Training Loss: 0.000862
Training Epoch: [33][12/22]	Training Loss: 0.001168
Training Epoch: [33][13/22]	Training Loss: 0.001470
Training Epoch: [33][14/22]	Training Loss: 0.001131
Training Epoch: [33][15/22]	Training Loss: 0.001039
Training Epoch: [33][16/22]	Training Loss: 0.001084
Training Epoch: [33][17/22]	Training Loss: 0.001353
Training Epoch: [33][18/22]	Training Loss: 0.000305
Training Epoch: [33][19/22]	Training Loss: 0.000771
Training Epoch: [33][20/22]	Training Loss: 0.000863
Training Epoch: [33][21/22]	Training Loss: 0.001039
Training Epoch: [33][22/22]	Training Loss: 0.004539
Validation Loss: 0.000446 	Validation Acc.: 98.371336
best accuracy: 99.0228013029316
Training Epoch: [34][0/22]	Training Loss: 0.001091
Training Epoch: [34][1/22]	Training Loss: 0.000717
Training Epoch: [34][2/22]	Training Loss: 0.001464
Training Epoch: [34][3/22]	Training Loss: 0.001656
Training Epoch: [34][4/22]	Training Loss: 0.000985
Training Epoch: [34][5/22]	Training Loss: 0.001901
Training Epoch: [34][6/22]	Training Loss: 0.000696
Training Epoch: [34][7/22]	Training Loss: 0.001328
Training Epoch: [34][8/22]	Training Loss: 0.000708
Training Epoch: [34][9/22]	Training Loss: 0.000682
Training Epoch: [34][10/22]	Training Loss: 0.001701
Training Epoch: [34][11/22]	Training Loss: 0.001061
Training Epoch: [34][12/22]	Training Loss: 0.001208
Training Epoch: [34][13/22]	Training Loss: 0.000634
Training Epoch: [34][14/22]	Training Loss: 0.000617
Training Epoch: [34][15/22]	Training Loss: 0.000213
Training Epoch: [34][16/22]	Training Loss: 0.001292
Training Epoch: [34][17/22]	Training Loss: 0.000755
Training Epoch: [34][18/22]	Training Loss: 0.001771
Training Epoch: [34][19/22]	Training Loss: 0.001152
Training Epoch: [34][20/22]	Training Loss: 0.000125
Training Epoch: [34][21/22]	Training Loss: 0.001172
Training Epoch: [34][22/22]	Training Loss: 0.000772
Validation Loss: 0.000581 	Validation Acc.: 97.394137
best accuracy: 99.0228013029316
Training Epoch: [35][0/22]	Training Loss: 0.002005
Training Epoch: [35][1/22]	Training Loss: 0.000606
Training Epoch: [35][2/22]	Training Loss: 0.002017
Training Epoch: [35][3/22]	Training Loss: 0.000997
Training Epoch: [35][4/22]	Training Loss: 0.000832
Training Epoch: [35][5/22]	Training Loss: 0.000463
Training Epoch: [35][6/22]	Training Loss: 0.001682
Training Epoch: [35][7/22]	Training Loss: 0.001479
Training Epoch: [35][8/22]	Training Loss: 0.000153
Training Epoch: [35][9/22]	Training Loss: 0.000678
Training Epoch: [35][10/22]	Training Loss: 0.000506
Training Epoch: [35][11/22]	Training Loss: 0.001101
Training Epoch: [35][12/22]	Training Loss: 0.000757
Training Epoch: [35][13/22]	Training Loss: 0.001731
Training Epoch: [35][14/22]	Training Loss: 0.001053
Training Epoch: [35][15/22]	Training Loss: 0.000834
Training Epoch: [35][16/22]	Training Loss: 0.000683
Training Epoch: [35][17/22]	Training Loss: 0.000537
Training Epoch: [35][18/22]	Training Loss: 0.000323
Training Epoch: [35][19/22]	Training Loss: 0.000999
Training Epoch: [35][20/22]	Training Loss: 0.000765
Training Epoch: [35][21/22]	Training Loss: 0.000465
Training Epoch: [35][22/22]	Training Loss: 0.000740
Validation Loss: 0.000401 	Validation Acc.: 98.371336
best accuracy: 99.0228013029316
Training Epoch: [36][0/22]	Training Loss: 0.000723
Training Epoch: [36][1/22]	Training Loss: 0.001661
Training Epoch: [36][2/22]	Training Loss: 0.001236
Training Epoch: [36][3/22]	Training Loss: 0.000925
Training Epoch: [36][4/22]	Training Loss: 0.000977
Training Epoch: [36][5/22]	Training Loss: 0.000558
Training Epoch: [36][6/22]	Training Loss: 0.000710
Training Epoch: [36][7/22]	Training Loss: 0.000406
Training Epoch: [36][8/22]	Training Loss: 0.001489
Training Epoch: [36][9/22]	Training Loss: 0.000778
Training Epoch: [36][10/22]	Training Loss: 0.000616
Training Epoch: [36][11/22]	Training Loss: 0.000634
Training Epoch: [36][12/22]	Training Loss: 0.000670
Training Epoch: [36][13/22]	Training Loss: 0.000783
Training Epoch: [36][14/22]	Training Loss: 0.001408
Training Epoch: [36][15/22]	Training Loss: 0.001229
Training Epoch: [36][16/22]	Training Loss: 0.001075
Training Epoch: [36][17/22]	Training Loss: 0.001494
Training Epoch: [36][18/22]	Training Loss: 0.000393
Training Epoch: [36][19/22]	Training Loss: 0.000463
Training Epoch: [36][20/22]	Training Loss: 0.000384
Training Epoch: [36][21/22]	Training Loss: 0.000993
Training Epoch: [36][22/22]	Training Loss: 0.002145
Validation Loss: 0.001126 	Validation Acc.: 96.742671
best accuracy: 99.0228013029316
Training Epoch: [37][0/22]	Training Loss: 0.000961
Training Epoch: [37][1/22]	Training Loss: 0.000528
Training Epoch: [37][2/22]	Training Loss: 0.000829
Training Epoch: [37][3/22]	Training Loss: 0.000894
Training Epoch: [37][4/22]	Training Loss: 0.000402
Training Epoch: [37][5/22]	Training Loss: 0.000906
Training Epoch: [37][6/22]	Training Loss: 0.000967
Training Epoch: [37][7/22]	Training Loss: 0.001164
Training Epoch: [37][8/22]	Training Loss: 0.000553
Training Epoch: [37][9/22]	Training Loss: 0.000240
Training Epoch: [37][10/22]	Training Loss: 0.000975
Training Epoch: [37][11/22]	Training Loss: 0.001020
Training Epoch: [37][12/22]	Training Loss: 0.001365
Training Epoch: [37][13/22]	Training Loss: 0.000107
Training Epoch: [37][14/22]	Training Loss: 0.001282
Training Epoch: [37][15/22]	Training Loss: 0.000750
Training Epoch: [37][16/22]	Training Loss: 0.000600
Training Epoch: [37][17/22]	Training Loss: 0.000712
Training Epoch: [37][18/22]	Training Loss: 0.000569
Training Epoch: [37][19/22]	Training Loss: 0.000497
Training Epoch: [37][20/22]	Training Loss: 0.001026
Training Epoch: [37][21/22]	Training Loss: 0.001462
Training Epoch: [37][22/22]	Training Loss: 0.000155
Validation Loss: 0.000628 	Validation Acc.: 98.371336
best accuracy: 99.0228013029316
Training Epoch: [38][0/22]	Training Loss: 0.001124
Training Epoch: [38][1/22]	Training Loss: 0.001723
Training Epoch: [38][2/22]	Training Loss: 0.001445
Training Epoch: [38][3/22]	Training Loss: 0.000827
Training Epoch: [38][4/22]	Training Loss: 0.000223
Training Epoch: [38][5/22]	Training Loss: 0.000834
Training Epoch: [38][6/22]	Training Loss: 0.000493
Training Epoch: [38][7/22]	Training Loss: 0.000749
Training Epoch: [38][8/22]	Training Loss: 0.000514
Training Epoch: [38][9/22]	Training Loss: 0.000683
Training Epoch: [38][10/22]	Training Loss: 0.000631
Training Epoch: [38][11/22]	Training Loss: 0.000216
Training Epoch: [38][12/22]	Training Loss: 0.000675
Training Epoch: [38][13/22]	Training Loss: 0.000424
Training Epoch: [38][14/22]	Training Loss: 0.000751
Training Epoch: [38][15/22]	Training Loss: 0.001408
Training Epoch: [38][16/22]	Training Loss: 0.000716
Training Epoch: [38][17/22]	Training Loss: 0.000918
Training Epoch: [38][18/22]	Training Loss: 0.000052
Training Epoch: [38][19/22]	Training Loss: 0.000589
Training Epoch: [38][20/22]	Training Loss: 0.000862
Training Epoch: [38][21/22]	Training Loss: 0.000452
Training Epoch: [38][22/22]	Training Loss: 0.000682
Validation Loss: 0.000577 	Validation Acc.: 98.697068
best accuracy: 99.0228013029316
Training Epoch: [39][0/22]	Training Loss: 0.000410
Training Epoch: [39][1/22]	Training Loss: 0.000537
Training Epoch: [39][2/22]	Training Loss: 0.000798
Training Epoch: [39][3/22]	Training Loss: 0.000642
Training Epoch: [39][4/22]	Training Loss: 0.000359
Training Epoch: [39][5/22]	Training Loss: 0.000230
Training Epoch: [39][6/22]	Training Loss: 0.001139
Training Epoch: [39][7/22]	Training Loss: 0.000517
Training Epoch: [39][8/22]	Training Loss: 0.000503
Training Epoch: [39][9/22]	Training Loss: 0.000627
Training Epoch: [39][10/22]	Training Loss: 0.000873
Training Epoch: [39][11/22]	Training Loss: 0.000296
Training Epoch: [39][12/22]	Training Loss: 0.000640
Training Epoch: [39][13/22]	Training Loss: 0.001083
Training Epoch: [39][14/22]	Training Loss: 0.000557
Training Epoch: [39][15/22]	Training Loss: 0.000734
Training Epoch: [39][16/22]	Training Loss: 0.000490
Training Epoch: [39][17/22]	Training Loss: 0.000953
Training Epoch: [39][18/22]	Training Loss: 0.000061
Training Epoch: [39][19/22]	Training Loss: 0.000995
Training Epoch: [39][20/22]	Training Loss: 0.001435
Training Epoch: [39][21/22]	Training Loss: 0.001067
Training Epoch: [39][22/22]	Training Loss: 0.000070
Validation Loss: 0.000866 	Validation Acc.: 97.719870
best accuracy: 99.0228013029316
Training Epoch: [40][0/22]	Training Loss: 0.000955
Training Epoch: [40][1/22]	Training Loss: 0.000684
Training Epoch: [40][2/22]	Training Loss: 0.000324
Training Epoch: [40][3/22]	Training Loss: 0.000278
Training Epoch: [40][4/22]	Training Loss: 0.000820
Training Epoch: [40][5/22]	Training Loss: 0.000670
Training Epoch: [40][6/22]	Training Loss: 0.001133
Training Epoch: [40][7/22]	Training Loss: 0.000538
Training Epoch: [40][8/22]	Training Loss: 0.001086
Training Epoch: [40][9/22]	Training Loss: 0.000685
Training Epoch: [40][10/22]	Training Loss: 0.000227
Training Epoch: [40][11/22]	Training Loss: 0.001206
Training Epoch: [40][12/22]	Training Loss: 0.000652
Training Epoch: [40][13/22]	Training Loss: 0.000190
Training Epoch: [40][14/22]	Training Loss: 0.001026
Training Epoch: [40][15/22]	Training Loss: 0.000266
Training Epoch: [40][16/22]	Training Loss: 0.000327
Training Epoch: [40][17/22]	Training Loss: 0.001255
Training Epoch: [40][18/22]	Training Loss: 0.000237
Training Epoch: [40][19/22]	Training Loss: 0.000352
Training Epoch: [40][20/22]	Training Loss: 0.000402
Training Epoch: [40][21/22]	Training Loss: 0.000078
Training Epoch: [40][22/22]	Training Loss: 0.000680
Validation Loss: 0.000703 	Validation Acc.: 98.045603
best accuracy: 99.0228013029316
Training Epoch: [41][0/22]	Training Loss: 0.000106
Training Epoch: [41][1/22]	Training Loss: 0.000687
Training Epoch: [41][2/22]	Training Loss: 0.001190
Training Epoch: [41][3/22]	Training Loss: 0.000774
Training Epoch: [41][4/22]	Training Loss: 0.000258
Training Epoch: [41][5/22]	Training Loss: 0.000184
Training Epoch: [41][6/22]	Training Loss: 0.001285
Training Epoch: [41][7/22]	Training Loss: 0.000716
Training Epoch: [41][8/22]	Training Loss: 0.000588
Training Epoch: [41][9/22]	Training Loss: 0.000399
Training Epoch: [41][10/22]	Training Loss: 0.000396
Training Epoch: [41][11/22]	Training Loss: 0.000604
Training Epoch: [41][12/22]	Training Loss: 0.000368
Training Epoch: [41][13/22]	Training Loss: 0.000179
Training Epoch: [41][14/22]	Training Loss: 0.000793
Training Epoch: [41][15/22]	Training Loss: 0.000518
Training Epoch: [41][16/22]	Training Loss: 0.001310
Training Epoch: [41][17/22]	Training Loss: 0.000715
Training Epoch: [41][18/22]	Training Loss: 0.000406
Training Epoch: [41][19/22]	Training Loss: 0.000140
Training Epoch: [41][20/22]	Training Loss: 0.000254
Training Epoch: [41][21/22]	Training Loss: 0.000440
Training Epoch: [41][22/22]	Training Loss: 0.000038
Validation Loss: 0.000893 	Validation Acc.: 97.719870
best accuracy: 99.0228013029316
Training Epoch: [42][0/22]	Training Loss: 0.000573
Training Epoch: [42][1/22]	Training Loss: 0.000485
Training Epoch: [42][2/22]	Training Loss: 0.000273
Training Epoch: [42][3/22]	Training Loss: 0.000219
Training Epoch: [42][4/22]	Training Loss: 0.001204
Training Epoch: [42][5/22]	Training Loss: 0.000783
Training Epoch: [42][6/22]	Training Loss: 0.000318
Training Epoch: [42][7/22]	Training Loss: 0.000421
Training Epoch: [42][8/22]	Training Loss: 0.000276
Training Epoch: [42][9/22]	Training Loss: 0.000271
Training Epoch: [42][10/22]	Training Loss: 0.000202
Training Epoch: [42][11/22]	Training Loss: 0.000448
Training Epoch: [42][12/22]	Training Loss: 0.000684
Training Epoch: [42][13/22]	Training Loss: 0.000426
Training Epoch: [42][14/22]	Training Loss: 0.001324
Training Epoch: [42][15/22]	Training Loss: 0.000466
Training Epoch: [42][16/22]	Training Loss: 0.000412
Training Epoch: [42][17/22]	Training Loss: 0.000797
Training Epoch: [42][18/22]	Training Loss: 0.000947
Training Epoch: [42][19/22]	Training Loss: 0.000345
Training Epoch: [42][20/22]	Training Loss: 0.001720
Training Epoch: [42][21/22]	Training Loss: 0.000330
Training Epoch: [42][22/22]	Training Loss: 0.000929
Validation Loss: 0.000815 	Validation Acc.: 98.045603
best accuracy: 99.0228013029316
Training Epoch: [43][0/22]	Training Loss: 0.000429
Training Epoch: [43][1/22]	Training Loss: 0.000473
Training Epoch: [43][2/22]	Training Loss: 0.000396
Training Epoch: [43][3/22]	Training Loss: 0.000827
Training Epoch: [43][4/22]	Training Loss: 0.001143
Training Epoch: [43][5/22]	Training Loss: 0.009815
Training Epoch: [43][6/22]	Training Loss: 0.000585
Training Epoch: [43][7/22]	Training Loss: 0.004136
Training Epoch: [43][8/22]	Training Loss: 0.020861
Training Epoch: [43][9/22]	Training Loss: 0.001673
Training Epoch: [43][10/22]	Training Loss: 0.000583
Training Epoch: [43][11/22]	Training Loss: 0.014822
Training Epoch: [43][12/22]	Training Loss: 0.002762
Training Epoch: [43][13/22]	Training Loss: 0.002298
Training Epoch: [43][14/22]	Training Loss: 0.003362
Training Epoch: [43][15/22]	Training Loss: 0.000428
Training Epoch: [43][16/22]	Training Loss: 0.000580
Training Epoch: [43][17/22]	Training Loss: 0.001650
Training Epoch: [43][18/22]	Training Loss: 0.002461
Training Epoch: [43][19/22]	Training Loss: 0.005551
Training Epoch: [43][20/22]	Training Loss: 0.002176
Training Epoch: [43][21/22]	Training Loss: 0.000839
Training Epoch: [43][22/22]	Training Loss: 0.000489
Validation Loss: 0.001265 	Validation Acc.: 98.697068
best accuracy: 99.0228013029316
Training Epoch: [44][0/22]	Training Loss: 0.001605
Training Epoch: [44][1/22]	Training Loss: 0.004581
Training Epoch: [44][2/22]	Training Loss: 0.002991
Training Epoch: [44][3/22]	Training Loss: 0.001056
Training Epoch: [44][4/22]	Training Loss: 0.013123
Training Epoch: [44][5/22]	Training Loss: 0.002174
Training Epoch: [44][6/22]	Training Loss: 0.000274
Training Epoch: [44][7/22]	Training Loss: 0.000949
Training Epoch: [44][8/22]	Training Loss: 0.006488
Training Epoch: [44][9/22]	Training Loss: 0.003312
Training Epoch: [44][10/22]	Training Loss: 0.004738
Training Epoch: [44][11/22]	Training Loss: 0.001892
Training Epoch: [44][12/22]	Training Loss: 0.000472
Training Epoch: [44][13/22]	Training Loss: 0.001107
Training Epoch: [44][14/22]	Training Loss: 0.000224
Training Epoch: [44][15/22]	Training Loss: 0.001614
Training Epoch: [44][16/22]	Training Loss: 0.003377
Training Epoch: [44][17/22]	Training Loss: 0.001794
Training Epoch: [44][18/22]	Training Loss: 0.006154
Training Epoch: [44][19/22]	Training Loss: 0.002757
Training Epoch: [44][20/22]	Training Loss: 0.004578
Training Epoch: [44][21/22]	Training Loss: 0.001002
Training Epoch: [44][22/22]	Training Loss: 0.000686
Validation Loss: 0.000831 	Validation Acc.: 98.697068
best accuracy: 99.0228013029316
Training Epoch: [45][0/22]	Training Loss: 0.000858
Training Epoch: [45][1/22]	Training Loss: 0.000680
Training Epoch: [45][2/22]	Training Loss: 0.002259
Training Epoch: [45][3/22]	Training Loss: 0.002041
Training Epoch: [45][4/22]	Training Loss: 0.001001
Training Epoch: [45][5/22]	Training Loss: 0.006530
Training Epoch: [45][6/22]	Training Loss: 0.012871
Training Epoch: [45][7/22]	Training Loss: 0.001267
Training Epoch: [45][8/22]	Training Loss: 0.001117
Training Epoch: [45][9/22]	Training Loss: 0.003811
Training Epoch: [45][10/22]	Training Loss: 0.004164
Training Epoch: [45][11/22]	Training Loss: 0.004564
Training Epoch: [45][12/22]	Training Loss: 0.002779
Training Epoch: [45][13/22]	Training Loss: 0.000239
Training Epoch: [45][14/22]	Training Loss: 0.000647
Training Epoch: [45][15/22]	Training Loss: 0.001861
Training Epoch: [45][16/22]	Training Loss: 0.005652
Training Epoch: [45][17/22]	Training Loss: 0.004862
Training Epoch: [45][18/22]	Training Loss: 0.020518
Training Epoch: [45][19/22]	Training Loss: 0.005701
Training Epoch: [45][20/22]	Training Loss: 0.000487
Training Epoch: [45][21/22]	Training Loss: 0.000767
Training Epoch: [45][22/22]	Training Loss: 0.037074
Validation Loss: 0.000788 	Validation Acc.: 97.719870
best accuracy: 99.0228013029316
Training Epoch: [46][0/22]	Training Loss: 0.001603
Training Epoch: [46][1/22]	Training Loss: 0.010140
Training Epoch: [46][2/22]	Training Loss: 0.045932
Training Epoch: [46][3/22]	Training Loss: 0.068981
Training Epoch: [46][4/22]	Training Loss: 0.003697
Training Epoch: [46][5/22]	Training Loss: 0.006075
Training Epoch: [46][6/22]	Training Loss: 0.040473
Training Epoch: [46][7/22]	Training Loss: 0.007318
Training Epoch: [46][8/22]	Training Loss: 0.005152
Training Epoch: [46][9/22]	Training Loss: 0.001554
Training Epoch: [46][10/22]	Training Loss: 0.001708
Training Epoch: [46][11/22]	Training Loss: 0.006791
Training Epoch: [46][12/22]	Training Loss: 0.008366
Training Epoch: [46][13/22]	Training Loss: 0.036999
Training Epoch: [46][14/22]	Training Loss: 0.004048
Training Epoch: [46][15/22]	Training Loss: 0.001945
Training Epoch: [46][16/22]	Training Loss: 0.003120
Training Epoch: [46][17/22]	Training Loss: 0.003704
Training Epoch: [46][18/22]	Training Loss: 0.019447
Training Epoch: [46][19/22]	Training Loss: 0.017500
Training Epoch: [46][20/22]	Training Loss: 0.017867
Training Epoch: [46][21/22]	Training Loss: 0.006163
Training Epoch: [46][22/22]	Training Loss: 0.001811
Validation Loss: 0.000577 	Validation Acc.: 98.371336
best accuracy: 99.0228013029316
Training Epoch: [47][0/22]	Training Loss: 0.005337
Training Epoch: [47][1/22]	Training Loss: 0.002788
Training Epoch: [47][2/22]	Training Loss: 0.008987
Training Epoch: [47][3/22]	Training Loss: 0.020209
Training Epoch: [47][4/22]	Training Loss: 0.027062
Training Epoch: [47][5/22]	Training Loss: 0.019894
Training Epoch: [47][6/22]	Training Loss: 0.011535
Training Epoch: [47][7/22]	Training Loss: 0.020660
Training Epoch: [47][8/22]	Training Loss: 0.004018
Training Epoch: [47][9/22]	Training Loss: 0.002930
Training Epoch: [47][10/22]	Training Loss: 0.016356
Training Epoch: [47][11/22]	Training Loss: 0.038896
Training Epoch: [47][12/22]	Training Loss: 0.009688
Training Epoch: [47][13/22]	Training Loss: 0.004394
Training Epoch: [47][14/22]	Training Loss: 0.004283
Training Epoch: [47][15/22]	Training Loss: 0.008904
Training Epoch: [47][16/22]	Training Loss: 0.009337
Training Epoch: [47][17/22]	Training Loss: 0.007820
Training Epoch: [47][18/22]	Training Loss: 0.028013
Training Epoch: [47][19/22]	Training Loss: 0.017942
Training Epoch: [47][20/22]	Training Loss: 0.004062
Training Epoch: [47][21/22]	Training Loss: 0.007866
Training Epoch: [47][22/22]	Training Loss: 0.003230
Validation Loss: 0.000672 	Validation Acc.: 96.742671
best accuracy: 99.0228013029316
Training Epoch: [48][0/22]	Training Loss: 0.006521
Training Epoch: [48][1/22]	Training Loss: 0.007164
Training Epoch: [48][2/22]	Training Loss: 0.004596
Training Epoch: [48][3/22]	Training Loss: 0.005968
Training Epoch: [48][4/22]	Training Loss: 0.016403
Training Epoch: [48][5/22]	Training Loss: 0.020410
Training Epoch: [48][6/22]	Training Loss: 0.005133
Training Epoch: [48][7/22]	Training Loss: 0.007254
Training Epoch: [48][8/22]	Training Loss: 0.010111
Training Epoch: [48][9/22]	Training Loss: 0.005682
Training Epoch: [48][10/22]	Training Loss: 0.005080
Training Epoch: [48][11/22]	Training Loss: 0.005358
Training Epoch: [48][12/22]	Training Loss: 0.004145
Training Epoch: [48][13/22]	Training Loss: 0.005092
Training Epoch: [48][14/22]	Training Loss: 0.003287
Training Epoch: [48][15/22]	Training Loss: 0.004790
Training Epoch: [48][16/22]	Training Loss: 0.014690
Training Epoch: [48][17/22]	Training Loss: 0.007066
Training Epoch: [48][18/22]	Training Loss: 0.008140
Training Epoch: [48][19/22]	Training Loss: 0.004234
Training Epoch: [48][20/22]	Training Loss: 0.004848
Training Epoch: [48][21/22]	Training Loss: 0.005120
Training Epoch: [48][22/22]	Training Loss: 0.006180
Validation Loss: 0.000667 	Validation Acc.: 96.742671
best accuracy: 99.0228013029316
Training Epoch: [49][0/22]	Training Loss: 0.006882
Training Epoch: [49][1/22]	Training Loss: 0.005815
Training Epoch: [49][2/22]	Training Loss: 0.003670
Training Epoch: [49][3/22]	Training Loss: 0.009768
Training Epoch: [49][4/22]	Training Loss: 0.008682
Training Epoch: [49][5/22]	Training Loss: 0.006536
Training Epoch: [49][6/22]	Training Loss: 0.009803
Training Epoch: [49][7/22]	Training Loss: 0.007362
Training Epoch: [49][8/22]	Training Loss: 0.003231
Training Epoch: [49][9/22]	Training Loss: 0.002359
Training Epoch: [49][10/22]	Training Loss: 0.003900
Training Epoch: [49][11/22]	Training Loss: 0.003375
Training Epoch: [49][12/22]	Training Loss: 0.003447
Training Epoch: [49][13/22]	Training Loss: 0.003814
Training Epoch: [49][14/22]	Training Loss: 0.003805
Training Epoch: [49][15/22]	Training Loss: 0.005496
Training Epoch: [49][16/22]	Training Loss: 0.004223
Training Epoch: [49][17/22]	Training Loss: 0.003497
Training Epoch: [49][18/22]	Training Loss: 0.003830
Training Epoch: [49][19/22]	Training Loss: 0.006458
Training Epoch: [49][20/22]	Training Loss: 0.003674
Training Epoch: [49][21/22]	Training Loss: 0.006033
Training Epoch: [49][22/22]	Training Loss: 0.006214
Validation Loss: 0.000509 	Validation Acc.: 98.045603
best accuracy: 99.0228013029316
Test Loss: 0.000252 	Test Acc.: 99.022801
